{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we need to read the data into a network that can be read by gephi, using networkx. We create nodes for each user and video and connect them via edges for each entry in the table (as each entry consists of a 'triangle'). Of course, we do not want any duplicates or self loops. We can then, using notworkx, write the data to a gexf file, which can be read by gephi.",
   "id": "1523a5fe6df8241a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T02:54:40.049225Z",
     "start_time": "2024-11-10T02:54:38.522048Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('pairwise_52seconds_share.csv')\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    user_1 = f\"user_{row['userID_1']}\"\n",
    "    user_2 = f\"user_{row['userID_2']}\"\n",
    "    video_node = f\"video_{row['videoID']}\"\n",
    "    \n",
    "    if not G.has_node(user_1):\n",
    "        G.add_node(user_1, type='user', color='blue')\n",
    "    \n",
    "    if not G.has_node(user_2):\n",
    "        G.add_node(user_2, type='user', color='blue')\n",
    "        \n",
    "    if not G.has_node(video_node):\n",
    "        G.add_node(video_node, type='video', color='green')\n",
    "        \n",
    "    G.add_edge(user_1, video_node, timestamp=row['timestamp_1'])\n",
    "    G.add_edge(user_2, video_node, timestamp=row['timestamp_2'])\n",
    "    G.add_edge(user_2, user_1, timestamp=row['timestamp_1'])\n",
    "    \n",
    "G.remove_edges_from(nx.selfloop_edges(G))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T02:54:40.247804Z",
     "start_time": "2024-11-10T02:54:40.056228Z"
    }
   },
   "cell_type": "code",
   "source": "nx.write_gexf(G, \"blue_helm.gexf\")\n",
   "id": "442947410e00cee3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the number of nodes and edges from the base network, we can then generate various other network types, to compare them to the base network. We choose here a watts strogatz model and a barabasi albert model, as both of these simulate the social media structure that we are expecting from the base network, and in which we want to find irregularities. The parameters here are easily imputed from the base network, k (for watts strogatz) is simply the average amound of connections per node in the base network (2m/n), and p is set to 0.1. This is the same for barabasi-albert too.",
   "id": "45aeefb254c06aec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T02:54:40.506693Z",
     "start_time": "2024-11-10T02:54:40.449289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "\n",
    "k = int((2 * m) / n)\n",
    "\n",
    "H = nx.watts_strogatz_graph(n= n, k = k, p = 0.1)\n",
    "\n",
    "nx.write_gexf(H, \"watts_strogatz_random.gexf\")"
   ],
   "id": "d1294373fa25502c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T02:54:40.680071Z",
     "start_time": "2024-11-10T02:54:40.517446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "m_par = int((2*m)/n)\n",
    "\n",
    "K = nx.barabasi_albert_graph(n = n, m = m_par)\n",
    "\n",
    "nx.write_gexf(K, \"barabasi_albert.gexf\")"
   ],
   "id": "18f7f3460ee0351d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can then define various metrics that we would like to assess for the different networks and apply them to compare.",
   "id": "8c39efb4befb85c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T04:41:15.949547Z",
     "start_time": "2024-11-10T04:41:15.942835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make sure to import python_louvain, not community\n",
    "import community.community_louvain as community_louvain\n",
    "\n",
    "# find triangles\n",
    "def transitivity(net):\n",
    "    return nx.transitivity(net)\n",
    "\n",
    "# this one doesnt work for some reason\n",
    "def rich_club(net):\n",
    "        largest_cc = max(nx.connected_components(net), key=len)\n",
    "        net_sub = net.subgraph(largest_cc)\n",
    "        return nx.rich_club_coefficient(net_sub)\n",
    "\n",
    "# average node degree (we might wanna make plots here to see how the degree varies in a curve, see below)\n",
    "def average_degree(net):\n",
    "    return sum(dict(net.degree()).values()) / net.number_of_nodes()\n",
    "\n",
    "# dont put this in the compare network function\n",
    "def plot_degree(net):\n",
    "    degrees = [d for n, d in net.degree()]\n",
    "    plt.hist(degrees)\n",
    "    plt.title('Degree Distribution')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# this shows if nodes of similar degrees are connected (-1 to 1)\n",
    "def deg_assortativity(net):\n",
    "    return nx.degree_assortativity_coefficient(net)\n",
    "\n",
    "# how likely are nodes neighbors also connected\n",
    "def clustering_coefficient(net):\n",
    "    return nx.average_clustering(net)\n",
    "\n",
    "def diameter(net):\n",
    "        largest_cc = max(nx.connected_components(net), key=len)\n",
    "        net_sub = net.subgraph(largest_cc)\n",
    "        return nx.diameter(net_sub)\n",
    "\n",
    "def avg_shortest_path(net):\n",
    "        largest_cc = max(nx.connected_components(net), key=len)\n",
    "        net_sub = net.subgraph(largest_cc)\n",
    "        return nx.average_shortest_path_length(net_sub)\n",
    "\n",
    "# this is for whether the network is easily divisible into communities (densely connected sub areas) (between 0 and 1)\n",
    "def modularity(net):\n",
    "    partition_dict = community_louvain.best_partition(net)\n",
    "    partition = []\n",
    "    for community_id in set(partition_dict.values()):\n",
    "        community_nodes = [node for node, community in partition_dict.items() if community == community_id]\n",
    "        partition.append(community_nodes)\n",
    "    return nx.algorithms.community.modularity(net, partition)\n",
    "\n",
    "# related to this (also dont put this in the compare network function)\n",
    "def plot_betweenness_centrality(net):\n",
    "    betweenness = nx.betweenness_centrality(net)\n",
    "    vals = list(betweenness.values())\n",
    "    plt.hist(vals)\n",
    "    plt.title('Betweenness Centrality Distribution')\n",
    "    plt.xlabel('Betweenness Centrality')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ],
   "id": "570ff31a3964beaa",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T04:41:16.353534Z",
     "start_time": "2024-11-10T04:41:16.349410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_networks(net, base_networks):\n",
    "    metrics = [transitivity, average_degree, deg_assortativity, diameter, avg_shortest_path, modularity]\n",
    "    metric_names = [metric.__name__ for metric in metrics]\n",
    "    \n",
    "    results = {metric_name: [] for metric_name in metric_names}\n",
    "    networks = [('blue_helm', net)] + [(f'baseline{i+1}', base_net) for i, base_net in enumerate(base_networks)]\n",
    "    \n",
    "    for name, network in networks:\n",
    "        for metric in metrics:\n",
    "            results[metric.__name__].append(metric(network))\n",
    "            \n",
    "    return results\n",
    "    "
   ],
   "id": "e61fdc7ad6cacc34",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T04:44:50.017350Z",
     "start_time": "2024-11-10T04:41:17.204166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "result = compare_networks(G, [H, K])"
   ],
   "id": "7b0d4aeaeacbe099",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can show the results by just printing this dictionary. The metrics are in the same order as the input in the compare networks function input.",
   "id": "671ad60e1340937e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T04:46:54.538077Z",
     "start_time": "2024-11-10T04:46:54.532586Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "25c3263814338583",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transitivity': [0.010092078570901202, 0, 0.0057534538480662],\n",
       " 'average_degree': [3.8392857142857144, 2.0, 5.9958791208791204],\n",
       " 'deg_assortativity': [-0.14743884690490577,\n",
       "  -0.05242977220982253,\n",
       "  -0.054575333420391205],\n",
       " 'diameter': [17, 398, 7],\n",
       " 'avg_shortest_path': [4.771102215238985,\n",
       "  151.35811512165415,\n",
       "  3.9733636430739705],\n",
       " 'modularity': [0.8138326916943203, 0.9692115705379781, 0.3890164963324232]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a160a2222449dbca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
